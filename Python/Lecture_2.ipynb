{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Advanced Python\n",
    "## ECON5170 Computational Methods in Economics\n",
    "#### Author: Zhentao Shi\n",
    "#### Date: March 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced R (Python)\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lecture, we will talk about efficient computation in R (Python).\n",
    "\n",
    "*  **R is a vector-oriented language. In most cases, vectorization speeds up computation**.\n",
    "*  We turn to more CPUs for parallel execution to save time if there is no more room to optimize the code to improve the speed.\n",
    "*  Clusters are accessed remotely. Communicating with a remote cluster is different from operating a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Despite mathematical equivalence, various ways of calculation can perform distinctively in terms of computational speed.\n",
    "\n",
    "Does computational speed matter?\n",
    "For a job that takes less than a minutes, the time difference is not a big deal.\n",
    "For modern economic structural estimation problems commonly seen in industrial organization, a single estimation can take up to a week. For those problems code optimization is essential.\n",
    "\n",
    "Other computational intensive procedures include bootstrap, simulated maximum likelihood and simulated method of moments. Even if a single execution does not take much time, repeating such a procedure for thousands of replications will consume a non-trivial duration.\n",
    "\n",
    "Of course, optimizing code takes human time. It is a balance of human time and machine time.\n",
    "\n",
    "__Example__\n",
    "\n",
    "The heteroskedastic-robust variance for the OLS regression is\n",
    "$$(X'X)^{-1} X'\\hat{e}\\hat {e}'X (X'X)^{-1}$$\n",
    "The difficult part is $X'\\hat{e}\\hat {e}'X=\\sum_{i=1}^n \\hat{e}_i^2 x_i x_i'$.\n",
    "There are at least 4 mathematically equivalent ways to compute this term.\n",
    "\n",
    "1.  literally sum over $i=1,\\dots,n$ one by one.\n",
    "2.  $X' \\mathrm{diag}(\\hat{e}^2) X$, with a dense central matrix.\n",
    "3.  $X' \\mathrm{diag}(\\hat{e}^2) X$, with a sparse central matrix.\n",
    "4.  Do cross product to `X*e_hat`. It takes advantage of the element-by-element operation.\n",
    "\n",
    "We first generate the data of binary response and regressors. Due to the discrete nature of the dependent variable, the error term in the linear probability model is heteroskedastic. It is necessary to use the heteroskedastic-robust variance to consistently estimate the asymptotic variance of the OLS estimator. The code chunk below estimates the coefficients and obtains the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NumPy library\n",
    "import numpy as np\n",
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "# Import the SciPy library\n",
    "from scipy.sparse import csr_matrix \n",
    "# Import the Random library\n",
    "import random\n",
    "# Import System Time\n",
    "import datetime\n",
    "# Import Math\n",
    "import math\n",
    "# Import statistics\n",
    "import statistics\n",
    "# Import MathPlotLib\n",
    "import matplotlib.pyplot as plt\n",
    "# Import Daytime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpm(n):\n",
    "    # estimation in a linear probability model\n",
    "    # set the parameters\n",
    "    b0 = np.array([[-1],[1]])\n",
    "    # generate the data\n",
    "    e = np.random.normal(size = (n,1))\n",
    "    X = np.ones((n,2))\n",
    "    X[:n, 1] = np.random.normal(n)\n",
    "    Y = np.dot(X, b0) + e\n",
    "    # note that in this regression b0 is not converge to b0 because the model is changed.\n",
    "    \n",
    "    # OLS estimation\n",
    "    bhat = np.dot(np.linalg.inv(np.matmul(X.T, X)), np.matmul(X.T, Y))\n",
    "    \n",
    "    # calculate the t-value\n",
    "    # bhat2 = bhat[[2]] # parameter we want to test\n",
    "    e_hat = Y - np.dot(X, bhat)\n",
    "    return(X, e_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the 4 estimators for the same data, and compare the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of robust variance matrix.\n",
    "# compare the implementation via matrix and vectorization.\n",
    "\n",
    "n = 5000\n",
    "Rep = 10\n",
    "\n",
    "# n = 50 \n",
    "# Rep = 1000\n",
    "\n",
    "for opt in range(0, 4):\n",
    "    \n",
    "    pts0 = datetime.datetime.now()\n",
    "    \n",
    "    for iter in range(Rep):\n",
    "        \n",
    "        np.random.seed(iter) # to make sure that the data used different estimation methods are the same \n",
    "    \n",
    "        dataXe = lpm(n)\n",
    "        X = dataXe[0]\n",
    "        e_hat = dataXe[1]\n",
    "        XXe2 = np.zeros((2,2))\n",
    "        \n",
    "        if opt == 0: # element by element\n",
    "            for i in range(len(X)):\n",
    "                XXe2 =  XXe2 + e_hat[i]**2 * np.dot(X[i,], (X[i,]).T)\n",
    "                \n",
    "        elif opt == 1: # the vectorized version\n",
    "            e_hatt = np.array(e_hat.T)\n",
    "            e_hatt2 = np.square(e_hatt)\n",
    "            e_hatt2_M = e_hatt2 * np.identity(n)\n",
    "            XXe2 = np.dot(X.T, np.dot(e_hatt2_M, X))\n",
    "            \n",
    "        elif opt == 2: # the vectorized version\n",
    "            e_hat2 = np.square(e_hat)\n",
    "            e_hat2_M = e_hat2 * np.identity(n)\n",
    "            e_hat2_M = csr_matrix(e_hat2_M)\n",
    "            XXe2 = np.dot(X.T, np.dot(e_hat2_M, X))\n",
    "        \n",
    "        elif opt == 3: # the best vectorization method. No waste\n",
    "            Xe = X * e_hat\n",
    "            XXe2 = np.matmul(Xe.T, Xe)\n",
    "            \n",
    "        XX_inv = np.matmul(X.T, X)\n",
    "        sig_B =  np.dot(XX_inv, np.dot(XXe2, XX_inv))\n",
    "    \n",
    "    print(\"n = \", n, \", Rep = \", Rep, \", opt = \", opt, \", time = \", datetime.datetime.now() - pts0, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results with n = 50 and Rep = 1000**\n",
    "\n",
    "n =  50 , Rep =  1000 , opt =  0 , time =  0:00:00.321856 \n",
    "\n",
    "n =  50 , Rep =  1000 , opt =  1 , time =  0:00:00.061392 \n",
    "\n",
    "n =  50 , Rep =  1000 , opt =  2 , time =  0:00:33.542949 \n",
    "\n",
    "n =  50 , Rep =  1000 , opt =  3 , time =  0:00:00.046890 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see the difference in running time, though the 4 methods are mathematically the same.\n",
    "When $n$ is small, `matrix` is fast and `Matrix` is slow; the vectorized version is the fastest.\n",
    "When $n$ is big, `matrix` is slow and `Matrix` is fast; the vectorized version is still the fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Loop\n",
    "\n",
    "In standard `for` loops, we have to do a lot of housekeeping work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI(x): # construct confidence interval\n",
    "           # x is a vector of random variables\n",
    "    n = len(x)\n",
    "    mu = statistics.mean(x)\n",
    "    sig = statistics.stdev(x)\n",
    "    upper = mu + 1.96 / math.sqrt(n) * sig\n",
    "    lower = mu - 1.96 / math.sqrt(n) * sig\n",
    "    return {'lower': lower, 'upper': upper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a standard `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  80.0 % \n",
      "\n",
      "0:00:00.057949 \n",
      "\n",
      "[False  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "# append a new outcome after each loop\n",
    "pts0 = datetime.datetime.now() # check time\n",
    "for i in range(Rep):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    out_i = ( ( bounds['lower'] <= mu  ) & (mu <= bounds['upper']) )\n",
    "    if i == 1:\n",
    "        out = np.array(out_i)\n",
    "    else:\n",
    "        out = np.append(out, out_i)\n",
    "\n",
    "stat_cover = np.count_nonzero(out)/Rep*100\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0 # check time elapse\n",
    "print(pts1, \"\\n\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical loop with an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  40.0 \n",
      "\n",
      "0:00:00.041532\n",
      "[True, True, False, True, False, False, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "# append a new outcome after each loop\n",
    "\n",
    "pts0 = datetime.datetime.now() # check time\n",
    "\n",
    "# Empty list\n",
    "out = list()\n",
    "\n",
    "\n",
    "for i in range(Rep):    \n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    out.append( ( bounds['lower'] <= mu  ) & (mu <= bounds['upper']) )\n",
    "\n",
    "stat_cover = out.count(True)/Rep*100\n",
    "\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0 # check time elapse\n",
    "print(pts1) \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical loop with an existing list and overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  50.0 \n",
      "\n",
      "0:00:00.457151\n"
     ]
    }
   ],
   "source": [
    "Rep = 100\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "# override an existing list\n",
    "\n",
    "pts0 = datetime.datetime.now() # check time\n",
    "\n",
    "# List with same length as Rep\n",
    "out = [0] * Rep\n",
    "\n",
    "for i in range(Rep):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    out.append((bounds['lower'] <= mu  ) & (mu <= bounds['upper']))\n",
    "\n",
    "stat_cover = out.count(True)/Rep*100\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0 # check time elapse\n",
    "print(pts1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the line `out = [0] * Rep`. It *pre-defines* a vector `out` to be filled by `out[i] = out.append((bounds['lower'] <= mu  ) & (mu <= bounds['upper']))`. The computer opens a continuous patch of memory for the vector `out`. When new result comes in, the old element is replaced. If we do not pre-define `out` but append one more element in each loop, the length of `out` will change in each replication and every time a new patch of memory will be assigned to store it. The latter approach will spend much more time just to locate the vector in the memory.\n",
    "\n",
    "`out` is the result container. In a `for` loop, we pre-define a container, and replace the elements\n",
    "of the container in each loop by explicitly calling the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  70.0 % \n",
      "\n",
      "0:00:00.062048\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "# Create a function and let it run with a for loop\n",
    "\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "\n",
    "pts0 = datetime.datetime.now()  # check time\n",
    "\n",
    "out = [capture(i) for i in range(Rep)]\n",
    "\n",
    "stat_cover = out.count(True)/Rep*100\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0  # check time elapse\n",
    "print(pts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply() has still some error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6fb377d0ef61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empirical coverage probability = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mRep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# empirical size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6fb377d0ef61>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empirical coverage probability = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mRep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# empirical size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "# Create a function and let it run with apply\n",
    "\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "\n",
    "pts0 = datetime.datetime.now()  # check time\n",
    "\n",
    "### apply ###\n",
    "from apply import apply\n",
    "\n",
    "\n",
    "out = [apply(capture, args=(i)) for x in range(Rep)]\n",
    "out = list(out)\n",
    "print(\"empirical coverage probability = \", out.count(True) / Rep * 100, \"\\n\")  # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0  # check time elapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  80.0 % \n",
      "\n",
      "[True, True, True, True, True, True, False, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "# Create a function and let it run with map\n",
    "\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "\n",
    "pts0 = datetime.datetime.now()  # check time\n",
    "\n",
    "out = map(capture, range(Rep), )\n",
    "out = list(out)\n",
    "stat_cover = out.count(True)/Rep*100\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "\n",
    "pts1 = datetime.datetime.now() - pts0  # check time elapse\n",
    "print(list(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Computing\n",
    "\n",
    "Parallel computing becomes essential when the data size is beyond the storage of a single computer, for example  {% cite li2018embracing %}.\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "The package `multiprocessing` is the choice for parallel computing in Python.\n",
    "Below is the basic structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "# import multiprocessing\n",
    "from multiprocessing import Process, current_process\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 5 1 0 0 7 1 3 3]\n",
      "[2 1 0 1 2 2 0 3 3 3]\n",
      "[1 2 1 2 2 1 4 1 1 0]\n",
      "[2 3 1 1 2 2 2 2 1 2]\n",
      "[5 1 1 2 2 0 1 5 0 1]\n",
      "[2 4 1 0 2 2 2 2 1 1]\n",
      "[3 0 2 2 5 3 5 2 3 4]\n",
      "[0 4 1 1 3 2 2 2 2 3]\n",
      "[4 0 2 3 3 2 0 1 1 1]\n",
      "[0 2 1 1 0 1 2 4 4 3]\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 10\n",
    "mu = 2\n",
    "\n",
    "for i in range(Rep):\n",
    "    np.random.seed(i)\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have two CPUs running simultaneously, in theory we can cut the time to a half of that on a single CPU. Is that what happening in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with the `process` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result: True\n",
      "The result: True\n",
      "The result: False\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: False\n",
      "The result: False\n",
      "The result: True\n",
      "empirical coverage probability =  0.0 % \n",
      "\n",
      "The the calculation time is: 0:00:00.284145 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "\n",
    "def capture(i,return_dict):\n",
    "    np.random.seed(i)\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    result = ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "    # process_id = os.getpid()\n",
    "    # print(\"Process ID: \" + str(process_id))\n",
    "    print(\"The result: \" + str(result))\n",
    "    return_dict[i]=result\n",
    "\n",
    "pts0 = datetime.datetime.now()  # check time\n",
    "\n",
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()\n",
    "jobs = []\n",
    "\n",
    "for i in range(Rep):\n",
    "    p = Process(target=capture, args=(i,return_dict))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for proc in jobs:\n",
    "    proc.join()\n",
    "\n",
    "# print(return_dict.values())\n",
    "\n",
    "stat_cover = jobs.count(True)/Rep*100\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0 # check time elapse\n",
    "print(\"The the calculation time is:\", pts1, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with the `pool` class & `apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  48.0 \n",
      "\n",
      "The the calculation time is: 0:00:01.718949 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rep = 200\n",
    "sample_size = 2000\n",
    "mu = 2\n",
    "\n",
    "\n",
    "pts0 = datetime.datetime.now()  # check time\n",
    "\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "\n",
    "# Only allows to run 4 processes at the time\n",
    "pool = mp.Pool(processes=4)\n",
    "\n",
    "# Initiate the multiprocess process wit apply()\n",
    "results = [pool.apply(capture, args=(i,)) for x in range(Rep)]\n",
    "\n",
    "print( \"empirical coverage probability = \", results.count(True)/Rep*100, \"\\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0 # check time elapse\n",
    "print(\"The the calculation time is:\", pts1, \"\\n\")\n",
    "# print(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with the `pool` class & `map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  50.0 \n",
      "\n",
      "The the calculation time is: 0:00:00.975129 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-210:\n",
      "Process ForkPoolWorker-212:\n",
      "Process ForkPoolWorker-211:\n",
      "Process ForkPoolWorker-209:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/marckullmann/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "Rep = 200\n",
    "sample_size = 2000\n",
    "mu = 2\n",
    "\n",
    "pts0 = datetime.datetime.now()  # check time\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "    \n",
    "# Only allows to run 4 processes at the time\n",
    "pool = mp.Pool(processes=4)\n",
    "\n",
    "# Initiate the multiprocess process with the map()\n",
    "results = pool.map(capture, range(Rep), )\n",
    "\n",
    "print( \"empirical coverage probability = \", results.count(True)/Rep*100, \"\\n\") # empirical size\n",
    "pts1 = datetime.datetime.now() - pts0 # check time elapse\n",
    "print(\"The the calculation time is:\", pts1, \"\\n\")\n",
    "# print(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Computing\n",
    "\n",
    "Investing money from our own pocket to an extremely powerful laptop to conduct heavy-lifting computational work\n",
    "is unnecessary. (i) We do not run these long jobs every day, it is more cost efficient\n",
    "to share a workhorse. (ii) We cannot keep our laptop always on when we move it\n",
    "around. The right solution is remote computing on a server.\n",
    "\n",
    "No fundamental difference lies between local and remote computing.\n",
    "We prepare the data and code, open a shell for communication, run the code, and collect the results.\n",
    "One potential obstacle is dealing with a command-line-based operation system.\n",
    "Such command line tools is the norm of life two or three decades ago, but today we mostly\n",
    "work in a graphic operating system like Windows or OSX.\n",
    "For Windows users (I am one of them), I recommend [PuTTY](http://www.putty.org/), a shell, and [WinSCP](http://winscp.net/eng/download.php), a graphic interface for input and output.\n",
    "\n",
    "Most servers in the world are running Unix/Linux operation system.\n",
    "Here are a few commands for basic operations.\n",
    "\n",
    "* mkdir\n",
    "* cd\n",
    "* copy\n",
    "* top\n",
    "* screen\n",
    "* ssh user@address\n",
    "* start a program\n",
    "\n",
    "Our department's computation infrastructure has been improving.\n",
    "A server dedicated to  professors is a 16-core machine. I have opened an account for you.\n",
    "You can try out this script on `econsuper`.\n",
    "\n",
    "1. Log in `econsuper.econ.cuhk.edu.hk`;\n",
    "2. Save the code block below as `loop_server.R`, and upload it to the server;\n",
    "3. In a shell, run `R --vanilla <loop_server.R> result_your_name.out`;\n",
    "4. To run a command in the background, add `&` at the end of the above command. To keep it running after closing the console, add `nohup` at the beginning of the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
